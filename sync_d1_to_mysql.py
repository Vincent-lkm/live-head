#!/usr/bin/env python3
"""
Script de synchronisation D1 Cloudflare vers MySQL
R√©cup√®re l'historique complet depuis l'API et l'ins√®re dans MySQL
"""

import requests
import mysql.connector
from mysql.connector import Error
import json
import time
from datetime import datetime
import sys
import argparse

# Configuration
CLOUDFLARE_API_URL = "https://live-head.restless-dust-dcc3.workers.dev/dump_last"
MYSQL_CONFIG = {
    'host': '138.201.84.171',
    'port': 3306,
    'user': 'vins',
    'password': 'LiveHead2024!Sync',
    'database': 'stats'
}

class D1ToMySQLSync:
    def __init__(self, dry_run=False):
        self.dry_run = dry_run
        self.connection = None
        self.cursor = None
        self.stats = {
            'total_fetched': 0,
            'new_records': 0,
            'duplicates': 0,
            'errors': 0
        }
    
    def connect_mysql(self):
        """√âtablit la connexion MySQL"""
        try:
            self.connection = mysql.connector.connect(**MYSQL_CONFIG)
            self.cursor = self.connection.cursor(dictionary=True)
            print(f"‚úÖ Connect√© √† MySQL: {MYSQL_CONFIG['host']}")
            return True
        except Error as e:
            print(f"‚ùå Erreur connexion MySQL: {e}")
            return False
    
    def fetch_from_cloudflare(self, limit=5000, offset=0):
        """R√©cup√®re les donn√©es depuis l'API Cloudflare"""
        try:
            url = f"{CLOUDFLARE_API_URL}?limit={limit}&offset={offset}"
            print(f"üì° R√©cup√©ration depuis Cloudflare (limit={limit}, offset={offset})...")
            
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            if data.get('ok'):
                return data.get('data', []), data.get('count', 0)
            else:
                print(f"‚ùå Erreur API: {data}")
                return [], 0
                
        except requests.RequestException as e:
            print(f"‚ùå Erreur lors de la r√©cup√©ration: {e}")
            return [], 0
    
    def get_existing_timestamps(self, sites):
        """R√©cup√®re les timestamps existants pour √©viter les doublons"""
        if not sites:
            return set()
        
        site_list = "','".join(sites)
        query = f"""
            SELECT CONCAT(site, '_', timestamp) as site_timestamp
            FROM site_status_interne
            WHERE site IN ('{site_list}')
        """
        
        try:
            self.cursor.execute(query)
            results = self.cursor.fetchall()
            return {row['site_timestamp'] for row in results}
        except Error as e:
            print(f"‚ùå Erreur r√©cup√©ration timestamps: {e}")
            return set()
    
    def insert_records(self, records):
        """Ins√®re les nouveaux enregistrements dans MySQL"""
        if not records:
            return
        
        # R√©cup√©rer les sites uniques
        sites = list(set(r['site'] for r in records))
        existing = self.get_existing_timestamps(sites)
        
        # Pr√©parer les donn√©es √† ins√©rer
        new_records = []
        for record in records:
            # Cr√©er l'identifiant unique
            site_timestamp = f"{record['site']}_{record.get('time', 0)}"
            
            if site_timestamp not in existing:
                new_records.append((
                    record['site'],
                    record.get('status', 0),
                    record.get('ms', 0),
                    record.get('pod', 'unknown'),
                    record.get('redir'),
                    1 if record.get('cross-domain') else 0,
                    record.get('time', 0)
                ))
            else:
                self.stats['duplicates'] += 1
        
        if new_records:
            if self.dry_run:
                print(f"üîç [DRY RUN] {len(new_records)} nouveaux enregistrements √† ins√©rer")
                return
            
            insert_query = """
                INSERT INTO site_status_interne 
                (site, status, ms, pod, redir, cross_domain, timestamp)
                VALUES (%s, %s, %s, %s, %s, %s, %s)
            """
            
            try:
                self.cursor.executemany(insert_query, new_records)
                self.connection.commit()
                self.stats['new_records'] += len(new_records)
                print(f"‚úÖ {len(new_records)} nouveaux enregistrements ins√©r√©s")
            except Error as e:
                print(f"‚ùå Erreur insertion: {e}")
                self.stats['errors'] += len(new_records)
                self.connection.rollback()
    
    def update_sync_metadata(self):
        """Met √† jour les m√©tadonn√©es de synchronisation"""
        if self.dry_run:
            print("üîç [DRY RUN] Mise √† jour des m√©tadonn√©es")
            return
        
        try:
            query = """
                UPDATE sync_metadata_status_interne 
                SET last_sync_timestamp = %s,
                    last_sync_date = NOW(),
                    total_records_synced = total_records_synced + %s,
                    last_sync_status = %s,
                    last_error_message = %s
                WHERE id = 1
            """
            
            status = 'success' if self.stats['errors'] == 0 else 'partial'
            error_msg = None if self.stats['errors'] == 0 else f"{self.stats['errors']} erreurs"
            
            self.cursor.execute(query, (
                int(time.time() * 1000),
                self.stats['new_records'],
                status,
                error_msg
            ))
            self.connection.commit()
            print("‚úÖ M√©tadonn√©es de synchronisation mises √† jour")
            
        except Error as e:
            print(f"‚ùå Erreur mise √† jour m√©tadonn√©es: {e}")
    
    def get_stats(self):
        """R√©cup√®re les statistiques de la base"""
        try:
            # Nombre total d'enregistrements
            self.cursor.execute("SELECT COUNT(*) as total FROM site_status_interne")
            total = self.cursor.fetchone()['total']
            
            # Nombre de sites uniques
            self.cursor.execute("SELECT COUNT(DISTINCT site) as sites FROM site_status_interne")
            sites = self.cursor.fetchone()['sites']
            
            # Derni√®re synchronisation
            self.cursor.execute("SELECT last_sync_date, total_records_synced FROM sync_metadata_status_interne WHERE id = 1")
            sync_info = self.cursor.fetchone()
            
            print("\nüìä Statistiques de la base:")
            print(f"   - Total enregistrements: {total:,}")
            print(f"   - Sites uniques: {sites:,}")
            if sync_info['last_sync_date']:
                print(f"   - Derni√®re sync: {sync_info['last_sync_date']}")
                print(f"   - Total synchronis√©: {sync_info['total_records_synced']:,}")
                
        except Error as e:
            print(f"‚ùå Erreur r√©cup√©ration stats: {e}")
    
    def sync(self, full_sync=False):
        """Lance la synchronisation"""
        print("üöÄ D√©marrage de la synchronisation D1 ‚Üí MySQL")
        print(f"   Mode: {'COMPLET' if full_sync else 'INCREMENTAL'}")
        if self.dry_run:
            print("   üîç MODE DRY RUN - Aucune modification ne sera effectu√©e")
        
        if not self.connect_mysql():
            return False
        
        try:
            offset = 0
            limit = 5000
            
            while True:
                # R√©cup√©rer les donn√©es
                records, total = self.fetch_from_cloudflare(limit, offset)
                
                if not records:
                    break
                
                self.stats['total_fetched'] += len(records)
                print(f"üì¶ Batch {offset//limit + 1}: {len(records)} enregistrements")
                
                # Ins√©rer les enregistrements
                self.insert_records(records)
                
                # Si on a r√©cup√©r√© moins que la limite, on a fini
                if len(records) < limit:
                    break
                
                offset += limit
                
                # Pause pour ne pas surcharger l'API
                time.sleep(0.5)
            
            # Mettre √† jour les m√©tadonn√©es
            self.update_sync_metadata()
            
            # Afficher les statistiques
            print("\n‚úÖ Synchronisation termin√©e!")
            print(f"   - Total r√©cup√©r√©: {self.stats['total_fetched']:,}")
            print(f"   - Nouveaux enregistrements: {self.stats['new_records']:,}")
            print(f"   - Doublons ignor√©s: {self.stats['duplicates']:,}")
            print(f"   - Erreurs: {self.stats['errors']:,}")
            
            # Afficher les stats de la base
            self.get_stats()
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erreur durant la synchronisation: {e}")
            return False
            
        finally:
            if self.cursor:
                self.cursor.close()
            if self.connection:
                self.connection.close()
                print("\nüîå Connexion MySQL ferm√©e")

def main():
    parser = argparse.ArgumentParser(description='Synchronise D1 Cloudflare vers MySQL')
    parser.add_argument('--dry-run', action='store_true', help='Mode test sans insertion')
    parser.add_argument('--full', action='store_true', help='Synchronisation compl√®te')
    
    args = parser.parse_args()
    
    syncer = D1ToMySQLSync(dry_run=args.dry_run)
    success = syncer.sync(full_sync=args.full)
    
    sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()